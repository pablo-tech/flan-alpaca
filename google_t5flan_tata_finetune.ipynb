{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU"
      ],
      "metadata": {
        "id": "7BK-6PrWiK34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "choqTBh0iPNn",
        "outputId": "dbe7138b-cdc1-4ddd-c37b-7bf01d8efcc9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug  5 15:42:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    46W / 400W |      3MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Installation\n",
        "\n",
        "https://pytorch.org/get-started/previous-versions/"
      ],
      "metadata": {
        "id": "SddyHdm7zMSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUDA 11.7"
      ],
      "metadata": {
        "id": "fPsy3TCq4Jrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CUDA 11.7\n",
        "TORCH_VERSION = \"2.0.0+cu117\"\n",
        "TORCH_VISION = \"0.15.1+cu117\"\n",
        "TORCH_AUDIO = \"2.0.1\"\n",
        "TORCH_TEXT = \"0.15.1\"\n",
        "TORCH_DATA = \"0.6.0\"\n",
        "BUILD_OPTIONS = \"--force-reinstall --no-deps\"\n",
        "BUILD_PATH = \"--index-url https://download.pytorch.org/whl/cu117\"\n",
        "\n",
        "!pip install torch==$TORCH_VERSION torchvision==$TORCH_VISION torchaudio==$TORCH_AUDIO torchtext==$TORCH_TEXT torchdata==$TORCH_DATA $BUILD_OPTIONS $BUILD_PATH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "JUXYjoSp2l4e",
        "outputId": "9b10a3db-4985-45e1-cf98-72474347dc51"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==2.0.0+cu117\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)\n",
            "Collecting torchvision==0.15.1+cu117\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torchvision-0.15.1%2Bcu117-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torchaudio-2.0.1%2Bcu117-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "Collecting torchtext==0.15.1\n",
            "  Using cached https://download.pytorch.org/whl/torchtext-0.15.1%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "Collecting torchdata==0.6.0\n",
            "  Using cached https://download.pytorch.org/whl/torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Installing collected packages: torchaudio, torchvision, torchtext, torchdata, torch\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.1+cu117\n",
            "    Uninstalling torchaudio-2.0.1+cu117:\n",
            "      Successfully uninstalled torchaudio-2.0.1+cu117\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu117\n",
            "    Uninstalling torchvision-0.15.1+cu117:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu117\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1+cpu\n",
            "    Uninstalling torchtext-0.15.1+cpu:\n",
            "      Successfully uninstalled torchtext-0.15.1+cpu\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.0\n",
            "    Uninstalling torchdata-0.6.0:\n",
            "      Successfully uninstalled torchdata-0.6.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu117\n",
            "    Uninstalling torch-2.0.0+cu117:\n",
            "      Successfully uninstalled torch-2.0.0+cu117\n",
            "Successfully installed torch-2.0.0+cu117 torchaudio-2.0.1+cu117 torchdata-0.6.0 torchtext-0.15.1+cpu torchvision-0.15.1+cu117\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvfuser",
                  "torch",
                  "torchaudio",
                  "torchdata",
                  "torchtext",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torchaudio, torchtext, torchdata\n",
        "\n",
        "torch.__version__, torchvision.__version__, torchaudio.__version__, torchtext.__version__, torchdata.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmhbDX4434RA",
        "outputId": "5561d25e-4c3f-4bb4-960b-f1a465ed8107"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.0.0+cu117', '0.15.1+cu117', '2.0.1+cu117', '0.15.1+cpu', '0.6.0')"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available(),"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhwGN974wrqU",
        "outputId": "fae4ef8c-0668-4184-9133-1c197529d60e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0), torch.backends.cudnn.version()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBFGafAozWtv",
        "outputId": "d877519c-00c0-4732-f797-0639bcb19f8b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('NVIDIA A100-SXM4-40GB', 8500)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Current CUDA Device does not support bfloat16\n",
        "\n",
        "Please switch dtype to float16: use A100 instead of V100, which does not support bfloat16\n"
      ],
      "metadata": {
        "id": "KJysvLOPHPNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Folders"
      ],
      "metadata": {
        "id": "p1HbT5eR725u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MY_DRIVE = \"/content/drive/MyDrive/\"\n",
        "\n",
        "%ls $MY_DRIVE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ7JsV7X76tQ",
        "outputId": "6b01edc5-1a2c-4007-9ce2-b6e649c3c7b9"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mTataLLM\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEV_HOME = MY_DRIVE + \"/TataLLM\"\n",
        "\n",
        "%ls $DEV_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEHyFgz1-uct",
        "outputId": "b9939b0e-d99a-4cc0-f037-067360c63fde"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mflan-alpaca-finetune\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# sys.path.append(\"TataLLM\")\n",
        "\n",
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnxF2F8uaENQ",
        "outputId": "7182a3f6-966b-4389-ef6a-8de2fda12c96"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python310.zip',\n",
              " '/usr/lib/python3.10',\n",
              " '/usr/lib/python3.10/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.10/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.10/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Git"
      ],
      "metadata": {
        "id": "pADdIPYYaB3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_NAME = \"flan-alpaca-finetune\"\n",
        "REPO_HOME = DEV_HOME + \"/\" + REPO_NAME"
      ],
      "metadata": {
        "id": "jjet29AQ_SaZ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHL3paq3Z9NU",
        "outputId": "e6b54bec-4965-40d9-ac1f-e4a5d88aaa3f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_ORIGIN = \"https://github.com/pablo-tech/\" + REPO_NAME + \".git\""
      ],
      "metadata": {
        "id": "NuZqnKPw_nnI"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf  $REPO_HOME\n",
        "\n",
        "%cd $DEV_HOME\n",
        "\n",
        "!git clone $REPO_ORIGIN"
      ],
      "metadata": {
        "id": "3SZOHW99aUAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff8a987-ff46-400d-aeac-8adf7d922f58"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TataLLM\n",
            "Cloning into 'flan-alpaca-finetune'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 135 (delta 34), reused 29 (delta 29), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (135/135), 51.69 KiB | 1.99 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls $REPO_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1PB9Nb-TpKg",
        "outputId": "f30d95da-ed88-40e5-f5d4-569ad65eed54"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_loading.py  LICENCE    requirements.txt                training.py\n",
            "inference.py     README.md  t5_fine_tune_with_alpaca.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "u_Gt2f6qpUst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REQUIREMENTS_FILE = REPO_HOME + \"/requirements.txt\""
      ],
      "metadata": {
        "id": "qpK0dPrRD_Qa"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls $REPO_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrZHvuvrpuED",
        "outputId": "478c4cd4-d12f-4320-a1a8-9b65430ffc54"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_loading.py  LICENCE    requirements.txt                training.py\n",
            "inference.py     README.md  t5_fine_tune_with_alpaca.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat $REQUIREMENTS_FILE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsTgybfkxL20",
        "outputId": "7de304b5-3921-48dd-e8f0-a6114684438a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TORCH\n",
            "fire==0.5.0\n",
            "pydantic==1.10.6\n",
            "pytorch-lightning==2.0.0\n",
            "transformers==4.28.1\n",
            "safetensors==0.3.0\n",
            "datasets==2.11.0\n",
            "git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "### APLACA\n",
            "install  \n",
            "multiprocess \n",
            "xxhash \n",
            "sentencepiece\n",
            "lightning_utilities \n",
            "torchmetrics \n",
            "accelerate \n",
            "tokenizers\n",
            "### HUGGINGFACE\n",
            "huggingface_hub\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r $REQUIREMENTS_FILE --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR1nOEvvpZuY",
        "outputId": "9958bb8d-4e9b-4f8b-ea00-51ec85db7eeb"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08 (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 8))\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision e536616888d51b453ed354a6f1e243fecb02ea08) to /tmp/pip-req-build-h0qffde4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-h0qffde4\n",
            "  Running command git rev-parse -q --verify 'sha^e536616888d51b453ed354a6f1e243fecb02ea08'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Running command git checkout -q e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Resolved https://github.com/huggingface/peft.git to commit e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fire==0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: pydantic==1.10.6 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 3)) (1.10.6)\n",
            "Requirement already satisfied: pytorch-lightning==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 5)) (4.28.1)\n",
            "Requirement already satisfied: safetensors==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: datasets==2.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 7)) (2.11.0)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 10)) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 11)) (0.70.15)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 13)) (0.1.99)\n",
            "Requirement already satisfied: lightning_utilities in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 15)) (1.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 16)) (0.21.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 17)) (0.13.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/requirements.txt (line 19)) (0.16.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "GwT1uNpPfN_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_HOME = \"/content/sample_data\"\n",
        "\n",
        "WORKING_DATA = DATA_HOME + \"/flan-alpaca\"\n",
        "\n",
        "DATA_PATH = WORKING_DATA + \"/data\"\n",
        "\n",
        "!ls $DATA_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0rQCXomA5hw",
        "outputId": "065c3299-1a1d-4d8c-a278-6261b1640279"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      flan-alpaca\t     README.md\n",
            "california_housing_test.csv   mnist_test.csv\n",
            "california_housing_train.csv  mnist_train_small.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALPACA_DATA = \"https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_data.json\"\n",
        "CLEANED_DATA = \"https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_data_cleaned.json\"\n",
        "GPT4_DATA = \"https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_gpt4_data.json\""
      ],
      "metadata": {
        "id": "FHue9a-GCFfV"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p $WORKING_DATA\n",
        "%mkdir -p $DATA_PATH\n",
        "\n",
        "%cd $DATA_PATH"
      ],
      "metadata": {
        "id": "QRtvA4fjfZEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a104b7-61fd-4b0d-d9bd-9b7fa9ca078b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data/flan-alpaca/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget $ALPACA_DATA -O $DATA_PATH/alpaca.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQPVgyJQfz7T",
        "outputId": "c0c411a4-02bb-4241-f8e6-2d8679727080"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-05 15:43:53--  https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_data.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/46c414c2-a137-464a-bd52-a65c9d63d69f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154353Z&X-Amz-Expires=300&X-Amz-Signature=b5c2cc5de62c1a1771e536b19068fde08e3a3f19b054abf4173b9e28424ff112&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_data.json&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-05 15:43:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/46c414c2-a137-464a-bd52-a65c9d63d69f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154353Z&X-Amz-Expires=300&X-Amz-Signature=b5c2cc5de62c1a1771e536b19068fde08e3a3f19b054abf4173b9e28424ff112&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_data.json&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22773992 (22M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/flan-alpaca/data/alpaca.json’\n",
            "\n",
            "/content/sample_dat 100%[===================>]  21.72M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-05 15:43:53 (148 MB/s) - ‘/content/sample_data/flan-alpaca/data/alpaca.json’ saved [22773992/22773992]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget $CLEANED_DATA -O $DATA_PATH/alpaca_clean.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVZi29bmgLYn",
        "outputId": "6def2c6f-b89c-4298-a2e8-4a5325b5874a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-05 15:43:53--  https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_data_cleaned.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/aea4d3aa-1557-481e-ae4b-b5feb26944a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154354Z&X-Amz-Expires=300&X-Amz-Signature=4396ef1c06ffb37436a472c622f0b2fde6d0e18b71d2d4ed71ad2a792109f96d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_data_cleaned.json&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-05 15:43:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/aea4d3aa-1557-481e-ae4b-b5feb26944a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154354Z&X-Amz-Expires=300&X-Amz-Signature=4396ef1c06ffb37436a472c622f0b2fde6d0e18b71d2d4ed71ad2a792109f96d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_data_cleaned.json&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22680910 (22M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/flan-alpaca/data/alpaca_clean.json’\n",
            "\n",
            "/content/sample_dat 100%[===================>]  21.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-05 15:43:54 (148 MB/s) - ‘/content/sample_data/flan-alpaca/data/alpaca_clean.json’ saved [22680910/22680910]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget $GPT4_DATA -O $DATA_PATH/alpaca_gpt4.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz52UC9cgUju",
        "outputId": "0ff1c9c1-0106-4b84-a55a-ac06c55ac8df"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-05 15:43:54--  https://github.com/declare-lab/flan-alpaca/releases/download/v0.1.0/alpaca_gpt4_data.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/f5c7c41a-6cc5-4836-814b-c8b1ef0c07b7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154354Z&X-Amz-Expires=300&X-Amz-Signature=19384183303bac5dba32de81aedb44127c8cf1cf3f0b58eb38193cfc029056bd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_gpt4_data.json&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-05 15:43:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617431627/f5c7c41a-6cc5-4836-814b-c8b1ef0c07b7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230805T154354Z&X-Amz-Expires=300&X-Amz-Signature=19384183303bac5dba32de81aedb44127c8cf1cf3f0b58eb38193cfc029056bd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617431627&response-content-disposition=attachment%3B%20filename%3Dalpaca_gpt4_data.json&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43379276 (41M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/flan-alpaca/data/alpaca_gpt4.json’\n",
            "\n",
            "/content/sample_dat 100%[===================>]  41.37M   119MB/s    in 0.3s    \n",
            "\n",
            "2023-08-05 15:43:55 (119 MB/s) - ‘/content/sample_data/flan-alpaca/data/alpaca_gpt4.json’ saved [43379276/43379276]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls $DATA_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap2uCQimDJGy",
        "outputId": "0b624a49-ff1d-4832-abac-51d5447e7800"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_clean.json  alpaca_gpt4.json  alpaca.json  train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-process Stanford Alpaca dataset"
      ],
      "metadata": {
        "id": "NCdo_WalgkOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install huggingface_hub multiprocess xxhash sentencepiece"
      ],
      "metadata": {
        "id": "1CTAN9xx806K"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_LOADING = REPO_HOME + \"/data_loading.py\""
      ],
      "metadata": {
        "id": "wvd9cGzcDs-L"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python $DATA_LOADING preprocess_alpaca \\\n",
        "--path_in $DATA_PATH/alpaca_gpt4.json \\\n",
        "--path_out $DATA_PATH/train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUXZG45ygnC5",
        "outputId": "ef0bc150-d848-4b26-b76b-9c2c7e67e3be"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"alpaca_samples\": 52002,\n",
            "  \"with_context\": 20679\n",
            "}\n",
            "{\n",
            "  \"source\": \"Suggest three steps for staying motivated\",\n",
            "  \"target\": \"Here are three steps for staying motivated:\\n\\n1. Set achievable goals: Set specific, measurable, and achievable goals for yourself. This will give you something to work towards, and the satisfaction of achieving your goals can help to keep you motivated.\\n\\n2. Reward yourself: When you achieve a goal or make progress towards it, celebrate your accomplishments by giving yourself a reward. This can be something as simple as treating yourself to your favorite food or taking a break and doing something you enjoy.\\n\\n3. Surround yourself with positivity: This can take many forms, such as surrounding yourself with positive people who can help support and motivate you, reading inspirational quotes or stories, or even listening to music that uplifts you. By filling your environment with positivity, you'll find it easier to stay motivated towards achieving your goals.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Write a few sentences explaining the concept of deep learning.\",\n",
            "  \"target\": \"Deep learning is a subset of machine learning, which itself is a subfield of artificial intelligence (AI). It's an advanced form of artificial neural networks that simulates the way the human brain processes data, learning to recognize patterns and features from vast amounts of data. Deep learning algorithms are designed to learn from experience, continuously improving their performance as they process more data. This makes them highly effective at tasks such as image and speech recognition, natural language processing, and other sophisticated AI applications.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Compare the uses of Machine Learning and Deep Learning.\",\n",
            "  \"target\": \"Machine Learning (ML) and Deep Learning (DL) are two subsets of Artificial Intelligence that have garnered a lot of attention in recent years. At their core, both involve training machines to learn from data, in order to make intelligent decisions and predictions. However, there are some fundamental differences in the way ML and DL are used, their architectures, and their applications.\\n\\nMachine Learning uses algorithms to analyze and learn from data, in order to make informed decisions. These algorithms can be broken down into two main types - supervised and unsupervised learning. Supervised learning involves training a model on a labeled data-set, where both inputs and outputs are known, and the algorithm learns the relationship between them. Unsupervised learning, on the other hand, deals with unlabeled data, where the algorithm must find patterns and relationships on its own. ML has a wide range of applications, from recommendation systems and image recognition, to natural language processing and even market analysis.\\n\\nDeep Learning, a subset of Machine Learning, is inspired by the structure and function of the human brain. It uses artificial neural networks (ANNs) to learn and make decisions. These neural networks consist of layers of interconnected nodes, where each layer processes the information received from the previous layer, and passes it on to the next. This multi-layered architecture allows DL to achieve incredible accuracy in tasks such as image and speech recognition, and natural language processing.\\n\\nIn summary, while both Machine Learning and Deep Learning are used for similar end goals, their architectures and methods vary. Deep Learning is usually more complex and requires more data to train, but can achieve higher accuracy in certain tasks. On the other hand, Machine Learning might be more suitable for less complex tasks, or for cases when the data-set is smaller. However, both ML and DL have proven to be incredibly powerful tools, and their uses will continue to expand and evolve as the field of AI progresses.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Come up with a survey to determine the overall mood of people in a given city.\",\n",
            "  \"target\": \"1. On a scale from 1-10, how happy are you feeling today?\\n2. Have you felt stressed or anxious in the past week?\\n3. Do you feel like your community is supportive and inclusive?\\n4. How satisfied are you with your personal life and relationships?\\n5. Do you feel safe and secure in your city?\\n6. Are there activities and events in the city that you enjoy participating in?\\n7. Are there enough opportunities for personal and professional growth in your city?\\n8. Are you happy with the services and facilities provided by your city government?\\n9. How often do you feel lonely or isolated?\\n10. Overall, would you say that your mood is generally positive, negative, or neutral?\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Create a program that reads an input number and prints its reverse.\",\n",
            "  \"target\": \"Here is one possible solution in Python:\\n\\n```python\\nnum = int(input(\\\"Enter a number: \\\"))\\nrev_num = 0\\n\\nwhile num > 0:\\n    remainder = num % 10\\n    rev_num = (rev_num*10) + remainder\\n    num = num // 10\\n\\nprint(f\\\"Reversed number is: {rev_num}\\\")\\n```\\n\\nThis solution prompts the user to enter a number, and stores it in a variable `num`. We initialize a variable `rev_num` to 0, which will represent the reversed number. The `while` loop will keep executing until the value of `num` becomes 0. Inside the loop, we calculate the remainder of `num` divided by 10, which returns the last digit of the number. Then, we add the last digit to `rev_num` after multiplying it by 10, which moves its decimal place to the left. We then remove the last digit of `num` by dividing it by 10 and using the floor operator `//` to discard its decimal places. When the loop finishes executing, the `rev_num` variable will contain the reversed number, which we print to the user.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Write a story about a robot who has to complete a difficult task.\",\n",
            "  \"target\": \"Once upon a time, in a world not so far away, there existed a robot named C-10. Engineered by a team of skilled scientists, C-10 was programmed to perform a variety of tasks with great precision and speed. The robot had helped humanity in many ways and had become the admiration of the world.\\n\\nOne day, a calamitous earthquake struck a small town, leaving behind a trail of devastation. Buildings had crumbled, roads had shattered, and cries for help could be heard all around. At once, the scientists who created C-10 were called upon, and they commissioned the robot to assist in the rescue efforts.\\n\\nC-10 arrived at the scene and analyzed the situation. Time was of the essence, and lives were at stake. The robot had to navigate through the debris, locate survivors, and transport them to safety. And to top it all, an aftershock was expected to strike at any moment. It was a challenging task, perhaps the most difficult the robot had ever encountered.\\n\\nWithout a moment's hesitation, C-10 sprang into action. With its advanced sensors, the robot scanned the area, searching for signs of life. As it moved through the rubble, C-10's strong arms lifted heavy objects, clearing a path for the rescue team. The robot worked tirelessly, evacuating people from the disaster zone, and transporting them to safety.\\n\\nJust as the aftershock struck, C-10 located the last of the survivors, and in a heroic effort, carried them to the safety zone. The ground shook, and the debris trembled, but C-10 stood firm.\\n\\nWhen the dust had settled, C-10 had saved countless lives, and had proved itself to be a true hero. The scientists who created the robot, as well as the people of the town, were proud of what C-10 had achieved, and grateful for the courageous acts that had been performed.\\n\\nFrom that day on, C-10 became an even greater source of admiration and inspiration to all, serving as a reminder that anything is possible, even in the direst of circumstances.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Compare the strengths and weaknesses of React and Angular\",\n",
            "  \"target\": \"React and Angular are two popular front-end web development frameworks used to build interactive and dynamic user interfaces. Here is a comparison of their strengths and weaknesses.\\n\\nReact:\\nStrengths:\\n- React's virtual DOM allows for efficient and fast rendering of components, leading to a smooth user experience.\\n- React is flexible and easy to learn, with a straightforward component-based architecture.\\n- Since it is backed by Facebook, React has a large and active community of developers, which results in regular updates and improvements.\\n- React can be used for both web and mobile app development, through React Native.\\n\\nWeaknesses:\\n- React is a library, not a full-fledged framework, so it does not provide features like routing and form validation out-of-the-box. Developers have to use additional libraries to incorporate these features.\\n- React's frequent updates can be a double-edged sword, as they can introduce breaking changes, making it challenging for developers to keep up.\\n\\nAngular:\\nStrengths:\\n- Angular is a full-fledged framework, providing a comprehensive set of features and tools for building complex web applications.\\n- It supports two-way data binding, which allows for real-time synchronization between the model and view.\\n- Angular has built-in dependency injection, making the code modular, reusable, and easier to test.\\n- Dependency injection also helps with code maintainability, making it easy to manage and update code in large-scale projects.\\n\\nWeaknesses:\\n- Angular has a steep learning curve due to its complex syntax and large set of concepts that developers need to understand.\\n- Since Angular is a heavyweight framework, it can be slower in performance compared to React, especially when dealing with large datasets.\\n\\nIn conclusion, both React and Angular have their strengths and weaknesses, and the choice between the two depends on the specific requirements and preferences of the developer or development team.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Identify one symbol and explain its meaning.\",\n",
            "  \"target\": \"The \\\"$\\\" symbol is commonly used to represent money, particularly the United States dollar. It can be used to express amounts of currency, such as \\\"$100,\\\" meaning one hundred dollars. The exact origins of the symbol are uncertain, but one popular theory is that it derives from the Spanish \\\"Peso de Ocho,\\\" also known as \\\"pieces of eight,\\\" which is a coin that was widely circulated in the Americas in the 18th and 19th centuries. The symbol itself is made up of an \\\"S\\\" with one or two vertical lines crossing through it. It is used in various contexts, including financial transactions, accounting, and pricing goods and services.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Make an inference about the following statement: \\\"I didn't know what to expect.\\\"\",\n",
            "  \"target\": \"Based on the statement \\\"I didn't know what to expect,\\\" it can be inferred that the speaker was uncertain or unsure about a particular situation or event, and did not have any preconceived notions or predictions about its outcome.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"List the steps you will take to create a budget\",\n",
            "  \"target\": \"Here are the steps to create a budget:\\n\\n1. Determine the purpose and time frame of the budget: Start by identifying the goal of the budget, for example, it could be for managing monthly expenses or for planning a big purchase or event. The time frame could be a week, month or year.\\n\\n2. Calculate your total income: Add up all sources of income such as your salary, interest or investment returns, and any other passive income streams.\\n\\n3. List all your expenses: Write down all your monthly expenses, including rent or mortgage, utilities, food, transportation, insurance, entertainment, and any other regular payments.\\n\\n4. Categorize your expenses: Group your expenses into categories such as housing, transportation, food, entertainment, and so on.\\n\\n5. Allocate funds for each category: Based on your income and your expenses, allocate a specific amount for each category in your budget. For example, if your monthly income is $5,000 and your rent is $1,000, allocate 20% for housing.\\n\\n6. Monitor and Adjust: Make sure to stay within the defined budget and track your spending to ensure that you do not exceed the allocated amounts for each category. Adjust your budget as needed, for example, you might want to increase the allocation for food expenses if you find that you are constantly going over the budgeted amount.\\n\\n7. Save for emergencies: It is wise to allocate some portion of your income for emergency expenses or rainy day funds. This will help you avoid taking on debt or overspending in case of unexpected expenses.\\n\\n8. Review and revise: Review your budget periodically and make adjustments as necessary. This will help you stay in control of your finances and achieve your financial goals.\"\n",
            "}\n",
            "{\n",
            "  \"total_samples\": 52002,\n",
            "  \"source\": \"{'min': 5, 'max': 544, 'median': 17, '95_percentile': 42}\",\n",
            "  \"target\": \"{'min': 2, 'max': 745, 'median': 108, '95_percentile': 415}\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Google T5"
      ],
      "metadata": {
        "id": "JF93zYE5hwtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TRAINING = REPO_HOME + \"/training.py\""
      ],
      "metadata": {
        "id": "dnUxIH8ZFFrQ"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_OUTPUT = REPO_HOME + \"/outputs\"\n",
        "MODEL_OUTPUT = TRAINING_OUTPUT + \"/model_xl\""
      ],
      "metadata": {
        "id": "4Wus1vWVEgaN"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p $TRAINING_OUTPUT\n",
        "%mkdir -p $MODEL_OUTPUT"
      ],
      "metadata": {
        "id": "juQ7NMKPE2-u"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install lightning_utilities torchmetrics accelerate tokenizers"
      ],
      "metadata": {
        "id": "LmYgZO-g-M2u"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python $MODEL_TRAINING \\\n",
        "--output_dir $MODEL_OUTPUT \\\n",
        "--use_compile \\\n",
        "--train_epochs 3 \\\n",
        "--max_source_length 64 \\\n",
        "--max_target_length 512 \\\n",
        "--data_path $DATA_PATH/train.json \\\n",
        "--model_name_or_path \"google/flan-t5-xl\" \\\n",
        "--train_batch_size 1 \\\n",
        "--gradient_accumulation_steps 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qw6uOR9FNsG",
        "outputId": "1dfd3091-8726-4533-a05d-b583191705d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-05 15:44:13.993675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Global seed set to 42\n",
            "\"data_path\":                   /content/sample_data/flan-alpaca/data/train.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 64\n",
            "\"learning_rate\":               0.0005\n",
            "\"max_source_length\":           64\n",
            "\"max_target_length\":           512\n",
            "\"model_name_or_path\":          google/flan-t5-xl\n",
            "\"output_dir\":                  /content/drive/MyDrive//TataLLM/flan-alpaca-finetune/outputs/model_xl\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            1\n",
            "\"train_epochs\":                3\n",
            "\"use_compile\":                 True\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    False\n",
            "\"weight_decay\":                0.0\n",
            "Loading checkpoint shards: 100% 2/2 [00:08<00:00,  4.06s/it]\n",
            "Downloading (…)neration_config.json: 100% 147/147 [00:00<00:00, 1.00MB/s]\n",
            "{'orig_state_dict': 560}\n",
            "Downloading (…)okenizer_config.json: 100% 2.54k/2.54k [00:00<00:00, 18.0MB/s]\n",
            "Downloading spiece.model: 100% 792k/792k [00:00<00:00, 14.3MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 29.1MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 15.9MB/s]\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type            | Params\n",
            "------------------------------------------\n",
            "0 | model | OptimizedModule | 2.8 B \n",
            "------------------------------------------\n",
            "2.8 B     Trainable params\n",
            "0         Non-trainable params\n",
            "2.8 B     Total params\n",
            "11,399.029Total estimated model params size (MB)\n",
            "/content/sample_data/flan-alpaca/data/train.json: 100% 52002/52002 [00:00<00:00, 101368.28it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/52002 [00:00<?, ?it/s] [2023-08-05 15:46:13,491] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "Epoch 0:  85% 44180/52002 [2:07:35<22:35,  5.77it/s, loss=1.940]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "XjiJXBO3kezJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install fire lightning_fabric peft"
      ],
      "metadata": {
        "id": "lJW2VNU7djr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_INFERENCE = REPO_HOME + \"/inference.py\"\n",
        "MODEL_CHECKPOINT = \"epoch=2-step=2439.ckpt\""
      ],
      "metadata": {
        "id": "0wAMdfjxc-Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls $MODEL_OUTPUT"
      ],
      "metadata": {
        "id": "JeNIx9Ekc5C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python $MODEL_INFERENCE test_model \\\n",
        "--path $MODEL_OUTPUT/$MODEL_CHECKPOINT \\\n",
        "--prompt \"Write an email about an alpaca that likes flan\""
      ],
      "metadata": {
        "id": "vwFw3AVpdHxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "- Intro to T5 https://colab.research.google.com/github/google-research/t5x/blob/main/t5x/notebooks/introduction.ipynb\n",
        "- T5 depp dive https://colab.research.google.com/github/google-research/t5x/blob/main/t5x/notebooks/training.ipynb#scrollTo=bqZYp90PIa1t\n",
        "- Alpaca T5 https://youtu.be/2jmZ1BIxD7Q\n",
        "- Cloned from https://github.com/declare-lab/flan-alpaca\n",
        "\n"
      ],
      "metadata": {
        "id": "rSLK0rXlZqyk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EeHLf6IfqjZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}